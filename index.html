<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Anand Pramod Aditya</title>
  <meta content="" name="description">
  <meta content="" name="keywords">
  
  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="container">

      <h1><a href="index.html" style="background: rgba(13, 13, 13, 0.7);">Anand Pramod Aditya</a></h1>
      <!-- Uncomment below if you prefer to use an image logo -->
      <!-- <a href="index.html" class="mr-auto"><img src="assets/img/logo.png" alt="" class="img-fluid"></a> -->
      <h2><a style="background: rgba(13, 13, 13, 0.7);">I'm a <span>Penultimate Year Computer Science student</span> in NTU</a></h2>

      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link active" href="#header">Home</a></li>
          <li><a class="nav-link" href="#about">About</a></li>
          <li><a class="nav-link" href="#services">Experience</a></li>
          <li><a class="nav-link" href="#projects">Projects</a></li>
          <li><a class="nav-link" href="#resume">CV</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

      <div class="social-links">
        <a href="https://github.com/apaditya7" class="twitter"><i class="ri-github-line"></i></a>
        <a href="https://www.linkedin.com/in/aditya-anand-pramod/" class="linkedin"><i class="bi bi-linkedin"></i></a>
      </div>

    </div>
  </header><!-- End Header -->

  <!-- ======= About Section ======= -->
  <section id="about" class="about">

    <!-- ======= About Me ======= -->
    <div class="about-me container">

      <div class="section-title">
        <h2>About</h2>
        <p>Learn more about me</p>
      </div>

      <div class="row">
        <div class="col-lg-4" data-aos="fade-right">
          <img src="assets/img/Profile_pic.jpeg" class="img-fluid" alt="">
        </div>
        <div class="col-lg-8 pt-4 pt-lg-0 content" data-aos="fade-left">
          <h3>Computer Science Penultimate Year Student</h3>
          <p class="fst-italic">
            Hey everyone I'm Aditya a 19 year old penultimate year computer science student at Nanyang Technological University. I picked up computing as a hobby in 2019 due to my previous interest in math and problem solving and have since fallen in love with the field, in specific it's application to data science and machine learning. 
          </p>
          <div class="row">
            <div class="col-lg-6">
              <ul>
                <li><i class="bi bi-chevron-right"></i> <strong>University:</strong> <span>Nanyang Technological University</span></li>
                <li><i class="bi bi-chevron-right"></i> <strong>Website:</strong> <span>Aditya.github.io</span></li>
                <li><i class="bi bi-chevron-right"></i> <strong>City:</strong> <span>Singapore</span></li>
                <li><i class="bi bi-chevron-right"></i> <strong>Home Town:</strong> <span>Chennai, India</span></li>
              </ul>
            </div>
            <div class="col-lg-6">
              <ul>
                <li><i class="bi bi-chevron-right"></i> <strong>Age:</strong> <span>19</span></li>
                <li><i class="bi bi-chevron-right"></i> <strong>Degree:</strong> <span>B.Comp in Computer Science</span></li>
                <li><i class="bi bi-chevron-right"></i> <strong>Email:</strong> <span>apaditya5674@gmail.com</span></li>
                <li><i class="bi bi-chevron-right"></i> <strong>Hobbies:</strong> <span>Long distance running,Football, Trying out new food.</span></li>
              </ul>
            </div>
          </div>
          <p>
            It is my dream to utilise my passion for technology and innovation to create a positive impact in this world and secure a future for myself.
            I aspire to get more opportunites to learn more and grow in the field that I'm passionate about.
          </p>
        </div>
      </div>

    </div><!-- End About Me -->

    <!-- ======= Counts ======= -->
    <div class="counts container">

      <div class="row">

        <div class="col-lg-3 col-md-6">
          <div class="count-box">
            <i class="bi bi-briefcase"></i>
            <span data-purecounter-start="0" data-purecounter-end="13" data-purecounter-duration="1" class="purecounter"></span>Months of <br>
            Internship Experience
          </div>
        </div>

        <div class="col-lg-3 col-md-6 mt-5 mt-md-0">
          <div class="count-box">
            <i class="bi bi-journal-richtext"></i>
            <span>4.4 / 5</span>
            CPGA <br> <p>Second Class Upper</p>
          </div>
        </div>

        <div class="col-lg-3 col-md-6 mt-5 mt-lg-0">
          <div class="count-box">
            <i class="bi bi-terminal"></i>
            <span data-purecounter-start="0" data-purecounter-end="10" data-purecounter-duration="1" class="purecounter">  </span>
            Technical <br> Projects
          </div>
        </div>

      </div>

    </div><!-- End Counts -->

    <!-- ======= Top Skills  ======= -->
    <div class="skills container">

      <div class="section-title">
        <h2>Top Skills</h2>
      </div>

      <div class="row skills-content">

        <div class="col-lg-6">

          <div class="progress">
            <span class="skill">Python <i class="val">Extremely Familiar</i></span>
            <div class="progress-bar-wrap">
              <div class="progress-bar" role="progressbar" aria-valuenow="100" aria-valuemin="0" aria-valuemax="100"></div>
            </div>
          </div>

          <div class="progress">
            <span class="skill">SQL<i class="val">Extremely Familiar</i></span>
            <div class="progress-bar-wrap">
              <div class="progress-bar" role="progressbar" aria-valuenow="95" aria-valuemin="0" aria-valuemax="100"></div>
            </div>
          </div>

          <div class="progress">
            <span class="skill">Machine Learning<i class="val">Familiar</i></span>
            <div class="progress-bar-wrap">
              <div class="progress-bar" role="progressbar" aria-valuenow="88" aria-valuemin="0" aria-valuemax="100"></div>
            </div>
          </div>

        </div>

        <div class="col-lg-6">

          <div class="progress">
            <span class="skill">Generative AI<i class="val">Familiar</i></span>
            <div class="progress-bar-wrap">
              <div class="progress-bar" role="progressbar" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100"></div>
            </div>
          </div>

          <div class="progress">
            <span class="skill">Scikit-Learn<i class="val">Familiar</i></span>
            <div class="progress-bar-wrap">
              <div class="progress-bar" role="progressbar" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100"></div>
            </div>
          </div>

          <div class="progress">
            <span class="skill">Javascript <i class="val">Decent</i></span>
            <div class="progress-bar-wrap">
              <div class="progress-bar" role="progressbar" aria-valuenow="70" aria-valuemin="0" aria-valuemax="100"></div>
            </div>
          </div>

        </div>

      </div>

    </div><!-- End Top Skills -->

    <!-- ======= All Skills ======= -->
    <div class="interests container">

      <div class="section-title">
        <h2>All Skills</h2>
      </div>

      <div class="row">
        <div class="col-lg-3 col-md-4">
          <div class="icon-box">
            <i class='bx bxl-python' style="color: #ffbb2c;"></i>
            <h3>Python</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4 mt-md-0">
          <div class="icon-box">
            <i class='bx bxl-postgresql' style="color: #5578ff;"></i>
            <h3>PostgreSQL</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4 mt-md-0">
          <div class="icon-box">
            <i class="bx bxl-postgresql" style="color: #29cc61;"></i>
            <h3>Microsoft SQL</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4 mt-lg-0">
          <div class="icon-box">
            <i class="bx bxl-java" style="color: #e80368;"></i>
            <h3>Java</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class="bx bxl-html5" style="color: #ff5828;"></i>
            <h3>HTML</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-css3' style="color: #47aeff;"></i>
            <h3>CSS</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxs-torch' style="color: #e361ff;"></i>
            <h3>PyTorch</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxs-camera' style="color: #ff5828;"></i>
            <h3>OpenCV</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-python' style="color: #335cff;"></i>
            <h3>TensorFlow</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-flask' style="color: #ffbb2c;"></i>
            <h3>Flask</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-docker' style="color: #47aeff;"></i>
            <h3>Docker</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-tux' style="color: #fafafa;"></i>
            <h3>Linux</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-react' style="color: #47aeff;"></i>
            <h3>React</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-google' style="color: #fafafa;"></i>
            <h3>Scikit-Learn</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class="ri-supabase-fill" style="color :#3ece22;"></i>
            <h3>Snowflake</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-aws' style="color: #ff5828;"></i>
            <h3>AWS </h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bx-data' style="color: #e80368"></i>
            <h3>Hadoop</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-mongodb' style="color: #3ece22;"></i>
            <h3>MongoDB</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='ri-supabase-fill' style="color: #fafafa;"></i>
            <h3>Spark</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-math' style="color: #3ece22;"></i>
            <h3>Airflow</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-google' style="color: #3ece22;"></i>
            <h3>Apache Kafka</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-python' style="color: #fafafa;"></i>
            <h3>Numpy</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-spring-boot' style="color: #3ece22;"></i>
            <h3>Langchain</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-spring-boot' style="color: #fafafa;"></i>
            <h3>CrewAI</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-python' style="color: #3ece22;"></i>
            <h3>LLama3</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-python' style="color: #ff5828;"></i>
            <h3>OpenAI</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-dev-to' style="color: #3ece22;"></i>
            <h3>HuggingFace</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-python' style="color: #ff5828;"></i>
            <h3>DeepLearning</h3>
          </div>
        </div>
        <div class="col-lg-3 col-md-4 mt-4">
          <div class="icon-box">
            <i class='bx bxl-github' style="color: #3ece22;"></i>
            <h3>Github</h3>
          </div>
        </div>
      </div>

    </div><!-- End All Skills -->
           
  </section><!-- End About Section -->

  <!-- ======= Resume Section ======= -->
  <section id="resume" class="resume">
    <div class="container">

      <div class="section-title">
        <h2>CV</h2>
        <p>Curriculum Vitae</p>
      </div>

      <div class="row">
        <div class="col-lg-6">
          <h3 class="resume-title">Internship Experience</h3>
          <div class="resume-item">
            <h4>Mobalytics</h4>
            <h5>Data Analyst Intern (Remote) </h5>
            <h6>June 2024 - Aug 2024</h6>
            <p>
            <ul>
              <li> Analyzed gaming industry trends and consumer insights to develop comprehensive reports and presentations, offering actionable recommendations for Mobalytics to expand its services to new game genres. </li>
              <li> Underwent training and research to gain domain-specific knowledge about the market and consumer behavior. </li>
              <li> Leveraged data visualization techniques to effectively present insights to the company and stakeholders using PowerBI and PowerPoint. </li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>AI Shophouse</h4>
            <h5>Data Science Intern</h5>
            <h6>May 2024 - Aug 2024</h6>
            <p>
            <ul>
              <li>Fine tuned the llama large language model to act as a personalised chatbot in the place of a speech therapist.</li>
              <li>Paired this fine tuned model with a speech to text transfomer model and a neural network that tested for speech accuracy to verify pronunciations of words. </li>
              <li>Lead a team of interns to deploy and develop several multi agent systems to help companies with Market and User research.</li>
              <li> Integrated these solutions with companies such as Coca Cola and Third eye.</li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>Oriental Aviation International</h4>
            <h5>Data Engineer Intern</h5>
            <h6>Jan 2024 - Apr 2024</h6>
            <p>
            <ul>
              <li>Developed and deployed an automated database management system using Sharepoint, SQL and Python.</li>
              <li>This involved handling large datasets of employee data and included work with real world data from 5+ countries in Asia.</li>
              <li>Prepared high level technical documentation for the working of the system as well as user manuals for future users. </li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>Everstone Capital</h4>
            <h5>Data Science Intern</h5>
            <h6>May 2024 - July 2024</h6>
            <p>
            <ul>
              <li>Collaborated with a portfolio company under everstone capital called GoGMGo. Spearheaded their first AI based application which was an inventory and invoice management system, that utilized OpenAI's models and langchain. </li>
              <li>Developed a content based filtering neural network to generate personalised recommendations for restaurants and food orders using Tensorflow and SQL.</li>
              <li>Integrated both these solutions into a react native application utilising RestAPIs.</li>
            </ul>
            </p>
          </div>
        </div>
        <div class="col-lg-6">
          <h3 class="resume-title">Education</h3>
          <div class="resume-item">
            <h4>Bachelor of Engineering (Computer Science)</h4>
            <h5>2020 - 2024</h5>
            <p><em>Nanyang Technological University, Singapore</em></p>
            <p>
              <ul>
                <li>Specialising in Data Science</li>
                <li>CGPA: 4.3 / 5.0 </li>
                <li>Relevant Courses: (1) Data Structures and Algorithms, (2) Natural Language Processing, (3) Machine Learning, (4) Database System Principles, (5) Object Oriented Programming, (6) Statistics, (7) Multi Disciplinary Project (8) Operating Systems</li>
              </ul>
            </p>
          </div>
          <h3 class="resume-title">Co Curricular Activities</h3>
          <div class="resume-item">
            <h4>Welfare Services Club</h4>
            <h5>Assistant Event Manager</h5>
            <h6>Aug 2023 - Aug 2024</h6>
            <p>
            <ul>
              <li> Administered the planning and oversight of the Growth and opportunites initiative at WSC </li>
              <li> Head of the liason division for the event </li>
              <li> Organised a volunteering and social events to raise awareness on mental health issues </li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>Quantitative Asset Management Club, NTU</h4>
            <h5>Member</h5>
            <h6>Aug 2023 - May 2024</h6>
            <p>
            <ul>
              <li> Learned the fundemental concepts of quantitative asset management,financial modeling, probability and statistics </li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>NTU Varsity Sports Association Cross Country</h4>
            <h5>Long Distance Runner</h5>
            <h6>Sep 2022 - Jul 2023</h6>
            <p>
            <ul>
              <li> Trained with the NTU Varsity Cross country team for track and field events</li>
              <li> Attended events as part of the NTU Team </li>
            </ul>
            </p>
          </div>
          <h3 class="resume-title">Certifications</h3>
          <div class="resume-item">
            <h4>Machine Learning Specialisation</h4>
            <h5>DeepLearning AI</h5>
            <p>
            <ul>
              <li> Learned to build and train reinforcement learning, supervised learning, and unsupervised learning ML models using Python. </li>
              <li>Developed recommender systems, neural networks, anomaly detection models, decision tree models, and regression models for regression, clustering,
                 and classification tasks using TensorFlow, Scikit-Learn, and PyTorch libraries in Python. </li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>Natural Language Process Specialisation</h4>
            <h5>DeepLearning AI</h5>
            <p>
            <ul>
              <li> Learned advanced NLP techniques such as logistic regression,Naive Bayes, RNNs,Embedders,LSTM models and used them to develop projects based on real data.  </li>
              <li>Worked with transformers to build sentence translators, autocorrect machines and build chatbots. </li>
              <li>Fine tuned the Bert LLM and the T5 Model to peform various operations such as question answering, chatbots, and text summarization.</li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>Data Science Professional Certificate</h4>
            <h5>IBM</h5>
            <p>
            <ul>
              <li> Learned Python and SQL skills and libraries to apply in the field of data science, completing things like build K nearest neighbours models, decision trees, web scarping models amongst others.  </li>
              <li> Learned the fundamentals of SQL and it's application in the fields of data analysis, visualisation and database management. </li>
              <li> Developed a comprehensive understanding of the entire data life cycle from the data preparation stage, to data processing, to cleaning, to analysis, to modeling and then visualisation. </li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>Data Engineer Professional Certificate</h4>
            <h5>IBM</h5>
            <p>
            <ul>
              <li> Learned to create and manage relational databases and apply database adminstration concepts using MySQL and PostgreSQL. </li>
              <li> Managed unstructued and Big Data using software such as MongoDB, Hadoop and Spark. Developed and Deployed Machine Learning Models using Python and Spark's freatures. </li>
              <li> Implemented ETL and ELT end to end pipelines using Bash, Airflow and Kafka, and created and deployed data warehouses and developed dashboards. </li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>Data Analytics Professional Certificate</h4>
            <h5>Google</h5>
            <p>
            <ul>
              <li> Gained an immersive understanding of the entire data analytics life cycle and the tools involved.  </li>
              <li> Developed experience in working with SQL and R for the data cleaning and transformation processes, and tools like Tabluea and Excel for the data visualsation and management.  </li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>Data Analytics Professional Certificate</h4>
            <h5>Google</h5>
            <p>
            <ul>
              <li> Gained an immersive understanding of the entire data analytics life cycle and the tools involved.  </li>
              <li> Developed experience in working with SQL and R for the data cleaning and transformation processes, and tools like Tabluea and Excel for the data visualsation and management.  </li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>Building Multi Agent Systems with CrewAI</h4>
            <h5>DeepLearning AI</h5>
            <p>
            <ul>
              <li> Gained an understanding into the workings and advantages of Agents, and how to develop agentic interactions and supplement Agents with tools.   </li>
              <li> Built projects with multi agent systems such as a Financial Analysis System, a Event Planning System and a Resume Builder.</li>
            </ul>
            </p>
          </div>
          <div class="resume-item">
            <h4>Langchain Chat with your Data</h4>
            <h5>DeepLearning AI</h5>
            <p>
            <ul>
              <li> Gained an understanding of langchain, it's purposes, features and workings. Additionally gained an understanding of of vector stores and embeddings. </li>
              <li> Developed a finetuned chatbot fed with local data and features like chat memory and RAG.</li>
            </ul>
            </p>
          </div>

          

          

        </div>
      </div>

    </div>
  </section><!-- End Resume Section -->

  <!-- ======= Experience Section ======= -->
  <section id="services" class="services">
    <div class="container">

      <div class="section-title">
        <h2>Experience</h2>
        <p>Internship Experience</p>
      </div>

      <div class="row">
        <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
          <div class="icon-box">
            <img src="./assets/img/company_logos/mobalytics.png" style="width: 80%; margin-bottom: 10%; height: 200px;">
            <h4><a href="">Data Analysis Intern</a></h4>
            <p>
              Analyzed gaming industry trends and consumer insights to develop comprehensive reports and presentations, offering actionable recommendations 
              for Mobalytics to expand its services to new game genres. Underwent training and research to gain domain-specific knowledge about the market 
              and consumer behavior. Leveraged data visualization techniques to effectively present insights to the company and stakeholders using PowerBI and PowerPoint.
            </p>
          </div>
        </div>

        <div class="col-lg-4 col-md-6 d-flex align-items-stretch mt-4 mt-md-0">
          <div class="icon-box">
            <img src="./assets/img/company_logos/aishop.png" style="width: 80%; margin-bottom: 10%; height: 200px;">
            <h4><a href="">Data Science Intern</a></h4>
            <p>
              Fine tuned the llama large language model to act as a personalised chatbot in the place of a speech therapist. 
              Paired this fine tuned model with a sound analysis based neural network that tested for speech accuracy to verify 
              pronunciations of words. Lead a team of interns to deploy and develop several multi agent systems to help companies 
              with Market and User research. Integrated these solutions with companies such as Coca Cola and Third eye.
            </p>
          </div>
        </div>

        <div class="col-lg-4 col-md-6 d-flex align-items-stretch mt-4 mt-lg-0">
          <div class="icon-box">
            <img src="./assets/img/company_logos/oai.png" style="width: 80%; margin-bottom: 10%; height: 200px;">
            <h4><a href="">Data Engineer Intern</a></h4>
            <p>
              Developed and deployed an automated database management system using Sharepoint, SQL and Python. 
              This involved handling large datasets of employee data and included work with real world data from 5+ countries in Asia. 
              Prepared high level technical documentation for the working of the system as well as user manuals for future users. 
            </p>
          </div>
        </div> 
        <div class="col-lg-4 col-md-6 d-flex align-items-stretch mt-4 mt-lg-0">
          <div class="icon-box">
            <img src="./assets/img/company_logos/Everstone.png" style="width: 80%; margin-bottom: 10%;">
            <h4><a href="">Data Science Intern</a></h4>
            <p>
              Collaborated with a portfolio company under everstone capital called GoGMGo. Spearheaded their first AI based application 
              which was an inventory and invoice management system, that utilized OpenAI's models and langchain. Developed a content 
              based filtering neural network to generate personalised recommendations for restaurants and food orders using Tensorflow and SQL. 
              Integrated both these solutions into a react native application utilising RestAPIs. 
            </p>
          </div>
        </div>          
      </div>

    </div>
  </section><!-- End Experience Section -->

  <!-- ======= Projects Section ======= -->
  <section id="projects" class="projects">
    <div class="container">

      <div class="section-title">
        <h2>Projects</h2>
        <p>Project Work</p>
      </div>

      <div class="row">

        <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
          <div class="icon-box">
            <img src="./assets/img/portfolio/DressSense.png" style="width: 100%; margin-bottom: 10%;">
            <h4>
              <a href="https://github.com/SENIORWOOFER/DressSense-App">DressSense-AI</a>
            </h4>
            <div class="row" style="display: flex; justify-content: center; flex-flow:row wrap;">
              <a href="https://github.com/SENIORWOOFER/DressSense-App" class="clickable-link">
                <i class='bx bxl-github'></i>
                <!-- Icons from https://boxicons.com/ -->
                <span class="text">Github</span>
              </a>
            </div>
            <p>
              DressSenseAI is an app that transforms unused garments into stylish outfits using AI and machine learning, 
              promoting sustainable fashion. Key features include wardrobe transformation, sustainability promotion, and 
              resale assistance. The app converts old clothes into trendy pieces, encourages the use of existing wardrobe items, 
              and helps users resell clothes by providing price suggestions and online marketplace recommendations. This offers a 
              cost-effective alternative to buying new clothes and contributes to reducing textile waste.

              The software used was Python, Javascript and React Native. Python was used for the backend to handle the image 
              processing, image generation and for the marketplace feature which was done by scraping similar items and their 
              details from online marketplaces and displaying them to the user. React Native was used for the front end to 
              develop and deploy the application and the front end and backend were connected through REST APIs. 
              The app also used a firebase database to store the wardbrobe information.
            </p>
            <div class="text-skills">
              <p>
                Large Language Models | Python | Image Processing | Image Generation | Natural Language Processing | Firebase | React Native
              </p>
            </div>
          </div>
        </div>

        <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
          <div class="icon-box">
            <img src="./assets/img/portfolio/Bin.png" style="width: 100%; margin-bottom: 10%;">
            <h4><a href="https://github.com/PrathamRanjan/The-Bin5.0-Environment">Bin5.0</a></h4>
            <div class="row" style="display: flex; justify-content: center; flex-flow:row wrap;">
              <a href="https://github.com/PrathamRanjan/The-Bin5.0-Environment" class="clickable-link">
                <i class='bx bxl-github'></i>
                <!-- Icons from https://boxicons.com/ -->
                <span class="text">Github</span>
              </a>
            </div>
            <p>
              The Bin5.0 is an auto-sorting Smart Sorter. This is thanks to our Smart Bin Sorter. 
              With our Smart Bin Cap, we can transform any bin into a Smart Bin that is capable of sorting recyclable
              trash into three distinct groups - plastic, glass, and metal. It does it automatically for the user, so all 
              they have to do is place their trash into the bin and it will sort it automatically for them. 
              This was built using a Raspberry PI, motion sensors and Python.

              The website was built using Python, it included features such as educational information, 
              recycling statistics, a map to the nearest recycling bin and an image recognition feature that told you 
              if an item was recyclable or not and how to deal with it.
            </p>
            <div class="text-skills">
              <p>
                Raspberry Pi | Python | Computer Vision | GenAI | Streamlit
              </p>
            </div>
          </div>
        </div>

        <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
          <div class="icon-box">
            <img src="./assets/img/portfolio/h4c.png" style="width: 100%; margin-bottom: 10%;">
            <h4><a>Hospital Website and Database Optimisation</a></h4>
            <p>
              Utilised HTML/CSS and Javascript to optimise the website of a local children's hospital improving site 
              efficiency and user navigation. Built an OCR system using Tesseract and Python to scan prescriptions 
              and automate the data entry process for patients. Additionally worked on enhancing the database and 
              cleaning the exsiting data to make it more organised.
            </p>
            <div class="text-skills">
              <p>
                HTML | CSS | Javascript | PostgreSQL | OCR | Python | Tesseract |
              </p>
            </div>
          </div>
        </div>

      </div>

      <div class="row">
        <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
          <div class="icon-box">
            <img src="./assets/img/portfolio/tesla.png" style="width: 100%; margin-bottom: 10%;">
            <h4><a>Tesla Stock Price Prediction Model</a></h4>
            <p>
              This forecasted Tesla's stock price by leveraging Twitter sentiment analysis and an LSTM Model. By collecting and 
              analyzing tweets related to Tesla using a pre-trained BERT model for sentiment classification, it calculated sentiment
              scores that, along with other financial indicators, were fed into a Long Short-Term Memory (LSTM) neural network.

              The LSTM model, was configured with two layers of 50 units each, a dropout rate of 0.2, and trained with the 
              Adam optimizer. The model processed features such as historical stock prices, trading volume, and sentiment scores 
              over a 30-day sequence length. Hyperparameters like batch size, sequence length, and learning rate were fine-tuned 
              to ensure the model's accuracy and prevent overfitting.
              
              Built entirely in Python, the project utilized TensorFlow for the LSTM model, Scikit-learn for data preprocessing 
              and evaluation, and Tweepy for Twitter API integration. 
            </p>
            <div class="text-skills">
              <p>
                Machine Learning | Data Science | Scikit-Learn | Transfomers | Pipelines | ETL Processes | LSTM Models
              </p>
            </div>
          </div>
        </div>

        <div class="col-lg-4 col-md-6 d-flex align-items-stretch mt-4 mt-lg-0">
          <div class="icon-box">
            <img src="./assets/img/portfolio/snowflake.png" style="width: 100%; margin-bottom: 10%;">
            <h4><a href="https://github.com/apaditya7/DiamondPricePredictor.git">Diamond Price Predictor</a></h4>
            <div class="row" style="display: flex; justify-content: center; flex-flow:row wrap;">
              <a href="https://github.com/apaditya7/DiamondPricePredictor.git" class="clickable-link">
                <i class='bx bxl-github'></i>
                <!-- Icons from https://boxicons.com/ -->
                <span class="text">Github</span>
              </a>
            </div>
            <p>
              Stored the data on snowflake as the data warehouse and loaded on to hex and used Snowpark and Scikit Learnt as the libraries
              for the projects. 
              
              Processed the data using Ordinal Encoders and MinMaxScalers to normalise the categorical columns. 
              The data was then loaded into a preprocessing pipeline and which was then used into the XGBoost Regression Model.
               The model was trained and then fine tuned it using Grid Search CV to find the best fitting for the model for 
               both the learning rate and the number of estimators.
               
               The fine tuned model then got a 98% accuracy score when testing the R^2 accuracy. The model was then 
               deployed it as a Vectorised User Defined Function.
            </p>
            <div class="text-skills">
              <p>
                XGBoost Model | Scikit-Learn | Snowpark | Data warehouse | Snowflake | MinMaxScalers | Model Evaluation|
              </p>
            </div>
          </div>  
        </div>
        
        <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
          <div class="icon-box">
            <img src="./assets/img/portfolio/stockprice.png" style="width: 100%; margin-bottom: 10%;">
            <h4><a href="https://github.com/apaditya7/FinancialAnalysisMultiAgentSystem.git">Financial Trading Multi Agent System</a></h4>
            <div class="row" style="display: flex; justify-content: center; flex-flow:row wrap;">
              <a href="https://github.com/apaditya7/FinancialAnalysisMultiAgentSystem.git" class="clickable-link">
                <i class='bx bxs-github'></i>
                <!-- Icons from https://boxicons.com/ -->
                <span class="text">Github</span>
              </a>
            </div>
            <p>
              Created several agents such as an  data analysis agent, a trading strategist agent, an execution agent and a
              risk management agent to work together to analyse a stock, come up with a strategy to invest in it and asses 
              it's benifits and risks.

              Fed the the agentic system with tools such as a web scraping tool and a website search tool to give it access 
              to the latest news about the stock. 

              Inputted my budget, the stock preference and my trading strategy preference and the agentic system 
              came up with a report highlighting a strategy recommendation, the risks and the advantages of investing in the stock. 

              Utilised CrewAI, OpenAI's model and Python to develop the multi agent system.

            </p>
            <div class="text-skills">
              <p>
                CrewAI | OpenAI | LLM | Web Scraping | JupyterNotebooks
              </p>
            </div>
          </div>
        </div>
      </div>

      <div class="row">
        <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
          <div class="icon-box">
            <img src="./assets/img/crewai.png" style="width: 100%; margin-bottom: 10%;">
            <h4><a href="https://github.com/apaditya7/EventPlanner.git">IntelliCheck</a></h4>
            <div class="row" style="display: flex; justify-content: center; flex-flow:row wrap;">
              <a href="https://github.com/apaditya7/EventPlanner.git" class="clickable-link">
                <i class='github'></i>
                <!-- Icons from https://boxicons.com/ -->
                <span class="text">Github</span>
              </a>
            </div>
            <p>
              Created several agents such as a venue coordinator agent, a logistics agent, a marketing agent to work together to plan an
               event and find out details such as an appropriate venue, itenary and marketing strategy.
              
              Fed the the agentic system with tools such as a web scraping tool and a website search tool to give it access to real time 
              data of the available venues.
              
              Inputted preferences, guest list, theme and budget and the agentic system outputted a report highlighting an available venue 
              that can accomodate the specified number of guests and match the theme.
              
              Utilised Python along with CrewAI for this agentic system. LLama3 was used as the Large Language Model along with Groq as the 
              cloud GPU.
            </p>
            <div class="text-skills">
              <p>
                LLama | Python | Web Scraping | Groq | Cloud GPU | CrewAI
              </p>
            </div>
          </div>
        </div>

        <div class="col-lg-4 col-md-6 d-flex align-items-stretch mt-4 mt-lg-0">
          <div class="icon-box">
            <img src="./assets/img/portfolio/mdp.png" style="width: 100%; margin-bottom: 10%;">
            <h4><a>Multi Disciplinary Design Project</a></h4>
            <p>
              Design a robot to complete a maze in the shortest time possible. The maze consists of a a series of obstacles to avoid. Each obstacle has a picture of a certain 
              letter or number attached to it. The robot has to navigate the maze, capture all the images, identify them, and send the results to an android tablet. Using a 
              four wheeled robot, STM Controller, Infrared Sensor, Ultrasound Sensor and Raspberry Pi.
            </p>
            <div class="text-skills">
              <p>
                TensorFlow Lite | Object Detection | Roboflow | Computer Vision | Raspberry Pi (Linux)
              </p>
            </div>
          </div>  
        </div>
        
        <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
          <div class="icon-box">
            <img src="./assets/img/portfolio/translator.png" style="width: 100%; margin-bottom: 10%;">
            <h4><a href="https://github.com/apaditya7/Translator.git">Translator Web App</a></h4>
            <div class="row" style="display: flex; justify-content: center; flex-flow:row wrap;">
              <a href="https://github.com/apaditya7/Translator.git" class="clickable-link">
                <i class='bx bx-github' ></i>
                <span class="text">Github</span>
              </a>
            </div>
            <p>
              Utilised a pre trained transformer model from hugging face to develop a translation application. 
              Built a pipeline and set it up as a function to accept an English sentence as an input. 
              Built a gradio interface that allowed the user to pick between the language they want the sentence to be 
              translated to and for the user to type in the English sentence. The output was then displayed on the user interface.
            </p>
            <div class="text-skills">
              <p>
                HuggingFace | Transfomers | Data Pipelines | Python | Gradio UI | NLP 
              </p>
            </div>
          </div>
        </div>
      </div>

      <div class="row">
        <div class="col-lg-4 col-md-6 d-flex align-items-stretch">
          <div class="icon-box">
            <img src="./assets/img/portfolio/sentiment.png" style="width: 100%; margin-bottom: 10%;">
            <h4><a href="https://github.com/apaditya7/SentimentClassifier.git">Sentiment Classifier</a></h4>
            <div class="row" style="display: flex; justify-content: center; flex-flow:row wrap;">
              <a href="https://github.com/apaditya7/SentimentClassifier.git" class="clickable-link">
                <i class='bx bx-github' ></i>
                <span class="text">Github</span>
              </a>
            </div>
            <p>
              Built a machine learning model for sentiment classification using Scikit Learn. 
              Collected a list of tweets and cleaned and processed the data. Then performed tokenisation on the dataset. 
              Built a pipeline to complete all the cleaning, transformation and tokenisation.
              The pipeline was then used to build a Naive Bayes classifier Model that successfully classified 
              the sentences into the appropriate sentiments.
            </p>
            <div class="text-skills">
              <p>
                NLP | Sentiment Analysis | Naive Bayes Model | Model Fine Tuning | Model Evaluation | Tokenisation | Scikit-Learn
              </p>
            </div>
          </div>
        </div>

      </div>

    </div>
  </section><!-- End Projects Section -->



   

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>